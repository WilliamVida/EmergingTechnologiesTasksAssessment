{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "These are my solutions to the Tasks 2020 assessment as part of my final year module Emerging Technologies. Authored by William Vida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Task 1: Write a Python function called ```sqrt2``` that calculates and prints to the screen the square root of 2 to 100 decimal places. Your code should not depend on any module from the standard library1 or otherwise. You should research the task first and include references and a description of your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research\n",
    "The square root of 2 can be calculated by using the Babylonian method [1] [2].\n",
    "\n",
    "$$ x_{0} \\approx \\sqrt{S}, $$ <br>\n",
    "$$ x_{n+1} = \\frac{1}{2} \\left (x_{n} + \\frac{S}{x_{n}} \\right), $$ <br>\n",
    "$$ \\sqrt{S} = \\lim_{n \\to \\infty} x_{n}. $$\n",
    "\n",
    "Procedures for finding the square root of a number have been known to the Babylonians from at least 1600 BC. YBC 7289 is a clay tablet which contains an approximation of the square root of 2 using base 60 to six decimal places [13].\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/YBC-7289-OBV-labeled.jpg/1280px-YBC-7289-OBV-labeled.jpg\" title=\"YBC 7289 tablet\" alt=\"YBC 7289 tablet\" width=\"60%\">\n",
    "\n",
    "The Babylonian method works by making an initial guess of the square root called $ x_{0} $ based on the square root $ S $. Then apply the formula to get a better approximation towards the square root until the approximation is the same as the previous iteration.\n",
    "\n",
    "Due to limitations with the floats in Python, it is not possible to print out a number to 100 decimal places [3]. One to way to overcome this limitation is by multiplying the answer by 10 ** 200 and then converting it to a string and then a list [4].\n",
    "\n",
    "### Example: Square Root of 2\n",
    "Make an initial guess of 1.2 and apply the formula to get a better approximation of the square root. $ S $ is 2.\n",
    "\n",
    "$ x_{0} \\approx 1.2 $\n",
    "\n",
    "$ x_{1} = \\frac{1}{2} \\left ({1.2} + \\frac{2}{{1.2}} \\right) = 1.433 $\n",
    "\n",
    "$ x_{2} = \\frac{1}{2} \\left ({1.433} + \\frac{2}{{1.433}} \\right) = 1.414 $\n",
    "\n",
    "$ x_{3} = \\frac{1}{2} \\left ({1.414} + \\frac{2}{{1.414}} \\right) = 1.414 $\n",
    "\n",
    "Hence $ \\sqrt{2} \\approx 1.414 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 2 is 1.4142135623730948729028552009655273607485832256919402696392729172311702355446324552662687021007677738\n"
     ]
    }
   ],
   "source": [
    "def sqrt2(S):\n",
    "    \"\"\"\n",
    "    A function to calculate the square root of 2 using the Babylonian method.\n",
    "    \"\"\"\n",
    "\n",
    "    # Guess of the approximation of the square root.\n",
    "    guess = S / 2.0\n",
    "\n",
    "    # Add 1 to the guess.\n",
    "    x = guess + 1\n",
    "\n",
    "    # Loop until the guess and x are the same.\n",
    "    while(guess != x):\n",
    "        # x becomes the value of the guess.\n",
    "        x = guess\n",
    "\n",
    "        # Formula is applied.\n",
    "        guess = (guess + (S / guess)) / 2    \n",
    "\n",
    "    # The task is to print out the number 2 to 100 decimal places and not any number. As such the below only works for 2.\n",
    "    if (S == 2):\n",
    "        # Increase the value of guess.\n",
    "        guess = guess * (10 ** 200)\n",
    "\n",
    "        # Get the guess without scientific notation.\n",
    "        answer = \"{0:.0f}\".format(guess)\n",
    "\n",
    "        # Convert the float to a string and then a list.\n",
    "        answer = str(answer)\n",
    "        answer = list(answer)\n",
    "\n",
    "        # Insert a decimal point.\n",
    "        answer.insert(1, \".\")\n",
    "\n",
    "        # Combine all the digits.\n",
    "        answer = \"\".join(answer)\n",
    "\n",
    "        # Set answer to 100 decimal places.\n",
    "        answer = answer[0:102]\n",
    "\n",
    "        return answer\n",
    "\n",
    "    # For any number other than 2.\n",
    "    else:\n",
    "        return guess\n",
    "\n",
    "print(\"The square root of 2 is \" + sqrt2(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 100 is 10.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Test the function on 100.\n",
    "print(\"The square root of 100 is {:.100f}\".format(sqrt2(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 5 is 2.2360679774997898050514777423813939094543457031250000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Test the function on 5.\n",
    "print(\"The square root of 5 is {:.100f}\".format(sqrt2(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 3 is 1.7320508075688771931766041234368458390235900878906250000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Test the function on 3.\n",
    "print(\"The square root of 3 is {:.100f}\".format(sqrt2(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 932 is 30.5286750449474979518527106847614049911499023437500000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Test the function on 932.\n",
    "print(\"The square root of 932 is {:.100f}\".format(sqrt2(932)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to calculate the square root of a number to 100 decimal places is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 2 is 1.4142135623730950488016887242096980785696718753769480731766797379907324784621070388503875343276415727\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/64278569\n",
    "def sqrt2V2(S):\n",
    "    x = S * 10 ** 200\n",
    "\n",
    "    r = x\n",
    "\n",
    "    def test_diffs(x, r):\n",
    "        d0 = abs(x - r ** 2)\n",
    "        dm = abs(x - (r - 1) ** 2)\n",
    "        dp = abs(x - (r + 1) ** 2)\n",
    "        minimised = d0 <= dm and d0 <= dp\n",
    "        below_min = dp < dm\n",
    "        return minimised, below_min\n",
    "\n",
    "    while True:\n",
    "        oldr = r\n",
    "        r = (r + x // r) // 2\n",
    "\n",
    "        minimised, below_min = test_diffs(x, r)\n",
    "        if minimised:\n",
    "            break\n",
    "\n",
    "        if r == oldr:\n",
    "            if below_min:\n",
    "                r += 1\n",
    "            else:\n",
    "                r -= 1\n",
    "            minimised, _ = test_diffs(x, r)\n",
    "            if minimised:\n",
    "                break\n",
    "\n",
    "    return f\"{r // 10 ** 100}.{r % 10 ** 100:0100d}\"\n",
    "\n",
    "print(\"The square root of 2 is \" + sqrt2V2(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 100 is 10.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Test the function on 100.\n",
    "print(\"The square root of 100 is \" + sqrt2V2(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 5 is 2.2360679774997896964091736687312762354406183596115257242708972454105209256378048994144144083787822750\n"
     ]
    }
   ],
   "source": [
    "# Test the function on 5.\n",
    "print(\"The square root of 5 is \" + sqrt2V2(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 3 is 1.7320508075688772935274463415058723669428052538103806280558069794519330169088000370811461867572485757\n"
     ]
    }
   ],
   "source": [
    "# Test the function on 3.\n",
    "print(\"The square root of 3 is \" + sqrt2V2(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 932 is 30.5286750449474960505118974012009591746573869572196530559322902661946981494994327711484788012736549011\n"
     ]
    }
   ],
   "source": [
    "# Test the function on 932.\n",
    "print(\"The square root of 932 is \" + sqrt2V2(932))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Methods of computing square roots; Babylonian method; https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method\n",
    "\n",
    "[2] Python Math: Computing square roots using the Babylonian method; Python Math: Exercise-18 with Solution; https://www.w3resource.com/python-exercises/math/python-math-exercise-18.php\n",
    "\n",
    "[3] 15. Floating Point Arithmetic: Issues and Limitations; https://docs.python.org/3/tutorial/floatingpoint.html\n",
    "\n",
    "[4] Is there a way to create more decimal points on Python without importing a library/module?; https://stackoverflow.com/a/64278569\n",
    "\n",
    "[13] YBC 7289; https://en.wikipedia.org/wiki/YBC_7289;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Task 2: The Chi-squared test for independence is a statistical hypothesis test like a t-test. It is used to analyse whether two categorical variables are independent. The Wikipedia article gives the table below as an example [4], stating the Chi-squared value based on it is approximately 24.6. Use ```scipy.stats``` to verify this value and calculate the associated p value. You should include a short note with references justifying your analysis in a markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second task is to verify the chi-squared value of approximately 24.6 using the data from the table below.\n",
    "\n",
    "|              \t| A   \t| B   \t| C   \t| D   \t| total \t|\n",
    "|--------------\t|-----\t|-----\t|-----\t|-----\t|-------\t|\n",
    "| White collar \t| 90  \t| 60  \t| 104 \t| 95  \t| 349   \t|\n",
    "| Blue collar  \t| 30  \t| 50  \t| 51  \t| 20  \t| 151   \t|\n",
    "| No collar    \t| 30  \t| 40  \t| 45  \t| 35  \t| 150   \t|\n",
    "| Total        \t| 150 \t| 150 \t| 200 \t| 150 \t| 650   \t|\n",
    "\n",
    "The null hypothesis is that each person's neighbourhood of residence is independent of the person's occupational classification.\n",
    "\n",
    "### Research\n",
    "A chi-square (χ2) statistic is a test that measures how a model compares to actual observed data. The data used in calculating a chi-square statistic must be random, raw, mutually exclusive, drawn from independent variables, and drawn from a large enough sample. For example, the results of tossing a fair coin meet these criteria [5].\n",
    "\n",
    "A p-value is used in hypothesis testing to help you support or reject the null hypothesis. The p-value is the evidence against a null hypothesis. The smaller the p-value, the stronger the evidence that you should reject the null hypothesis [8].\n",
    "\n",
    "The formula to calculate the expected value for a cell is: [6]\n",
    "\n",
    "$$ E_{ij} = \\frac{R_iC_j}{N} $$\n",
    "\n",
    "Where\n",
    "<br>$ R $  = row\n",
    "<br>$ C $ = column\n",
    "<br>$ N $ = total\n",
    "<br>for $i$th row and $j$th column\n",
    "\n",
    "The chi-squared formula is: [7]\n",
    "\n",
    "$$ \\chi^2_c = \\frac{(O_i - E_i)^2}{E_i} $$\n",
    "\n",
    "Where\n",
    "<br>$ c $ = degrees of freedom\n",
    "<br>$ {O}_i $ =\tobserved value\n",
    "<br>$ E_{i}\t$ =\texpected value\n",
    "\n",
    "### Example: Calculating the Expected Value of White-Collar Workers for Column A\n",
    "Calculating the expected value of white-collar workers for column A would be as follows:\n",
    "\n",
    "$ E = \\frac{349 \\times 150}{650} $\n",
    "\n",
    "$ E \\approx 80.5385 $\n",
    "\n",
    "Then use the chi-square formula where, in this case, the observed value of $ O $ is 90 and the expected value of $ E $ is 80.5385:\n",
    "\n",
    "$ \\chi^2 = \\frac{(90 - 80.5385)^2}{80.5385} $\n",
    "\n",
    "$ \\chi^2 \\approx 1.1115 $\n",
    "\n",
    "Doing this for all cells and adding them together will give an approximate value of 24.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2: 24.5712028585826\n",
      "p-value: 0.0004098425861096696\n",
      "degrees of freedom: 6\n",
      "expected frequencies:\n",
      "[[ 80.53846154  80.53846154 107.38461538  80.53846154]\n",
      " [ 34.84615385  34.84615385  46.46153846  34.84615385]\n",
      " [ 34.61538462  34.61538462  46.15384615  34.61538462]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\"\"\"\n",
    "Code to get chi-squared statistics for the data in the table.\n",
    "\"\"\"\n",
    "\n",
    "# Populate the arrays.\n",
    "whiteCollar = [90, 60, 104, 95]\n",
    "blueCollar = [30, 50, 51, 20]\n",
    "noCollar = [30, 40, 45, 35]\n",
    "\n",
    "data = [whiteCollar, blueCollar, noCollar]\n",
    "\n",
    "# Contingency table.\n",
    "chi2, p, dof, ex = stats.chi2_contingency(data)\n",
    "\n",
    "# Print out the values.\n",
    "print(\"chi2:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"degrees of freedom:\", dof)\n",
    "print(\"expected frequencies:\")\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The p-value of the data is 0.0004098425861096696. As this p-value is less than 0.05 it is statistically significant against the \n",
    "null hypothesis. Therefore, we must reject the null hypothesis which states that each person's neighbourhood of residence is independent of the person's occupational classification [9]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[5] Chi-Square (χ2) Statistic Definition; What Is a Chi-Square Statistic?; https://www.investopedia.com/terms/c/chi-square-statistic.asp;\n",
    "\n",
    "[6] The chi-square test; Getting expected values; https://web.stanford.edu/class/psych252/cheatsheets/chisquare.html;\n",
    "\n",
    "[7] Chi-Square (χ2) Statistic Definition; The Formula for Chi-Square Is; https://www.investopedia.com/terms/c/chi-square-statistic.asp;\n",
    "\n",
    "[8] P Value Definition; https://www.statisticshowto.com/p-value/;\n",
    "\n",
    "[9] What a p-value tells you about statistical significance; https://www.simplypsychology.org/p-value.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Task 3: The standard deviation of an array of numbers ```x``` is calculated using ```numpy``` as ```np.sqrt(np.sum((x - np.mean(x))**2)/len(x)) ```. However, Microsoft Excel has two different versions of the standard deviation calculation, ```STDEV.P``` and ```STDEV.S ```. The ```STDEV.P``` function performs the above calculation but in the ```STDEV.S``` calculation the division is by ```len(x)-1``` rather than ```len(x) ```. Research these Excel functions, writing a note in a Markdown cell about the difference between them. Then use ```numpy``` to perform a simulation demonstrating that the ```STDEV.S``` calculation is a better estimate for the standard deviation of a population when performed on a sample. Note that part of this task is to figure out the terminology in the previous sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research\n",
    "A standard deviation is the measure of the spread of data values [11]. Assuming the data is normally distributed, 68% of the values are within one standard deviation of the mean, 95% are within two standard deviations and 99.7% are within three standard deviations [12].\n",
    "\n",
    "#### Difference Between ```STDEV.P``` and ```STDEV.S```\n",
    "The ```STDEV.P``` function is used for data representing the entire population while the ```STDEV.S``` function is used for data that is a sample of the population [10].\n",
    "\n",
    "The formula for calculating the standard deviation for a population is: [10]\n",
    "\n",
    "$$ \\sigma = {\\sqrt {\\frac {\\sum(x_{i}-{\\mu})^{2}}{N}}} $$\n",
    "\n",
    "Where\n",
    "<br>$ \\sigma $ = population standard deviation\n",
    "<br>$ N $ =\tthe size of the population\n",
    "<br>$ x_i $\t= each value from the population\n",
    "<br>$ \\mu $ = the population mean\n",
    "\n",
    "The formula for calculating the standard deviation for a sample is:\n",
    "\n",
    "$$ s = {\\sqrt {\\frac {\\sum _{i=1}^{N}(x_{i}-{\\overline {x}})^{2}}{N - 1}}} $$\n",
    "\n",
    "Where\n",
    "<br>$ s $ = sample standard deviation\n",
    "<br>$ N $ = the number of observations\n",
    "<br>$ x_i $ = the observed values of a sample item\n",
    "<br>$\\overline {x} $ = the mean value of the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n",
    "\n",
    "# Create data that is normally distributed.\n",
    "loc = 100\n",
    "scale = 10\n",
    "size = 10000\n",
    "\n",
    "data = np.random.normal(loc, scale, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the data 100.04112334438436\n"
     ]
    }
   ],
   "source": [
    "# Mean of the data.\n",
    "print(\"Mean of the data\", np.mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation population (STDEV.P) 9.977360721310788\n"
     ]
    }
   ],
   "source": [
    "# Standard deviation population (STDEV.P) function on the population.\n",
    "def STDEV_P(x):\n",
    "    return np.sqrt(np.sum((x - np.mean(x)) ** 2) / len(x))\n",
    "\n",
    "print(\"Standard deviation population (STDEV.P)\", STDEV_P(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation sample (STDEV.S) 9.977859626765074\n"
     ]
    }
   ],
   "source": [
    "# Standard deviation sample (STDEV.S) function on the population.\n",
    "def STDEV_S(x):\n",
    "    return np.sqrt(np.sum((x - np.mean(x)) ** 2) / (len(x) - 1))\n",
    "\n",
    "print(\"Standard deviation sample (STDEV.S)\", STDEV_S(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDEV.P of the population 9.977360721310788\n",
      "\n",
      "STDEV.S of the sample data: 10.045464657717417\n",
      "Accuracy (closer to 100% is more accurate): 100.6825846865611 %\n",
      "\n",
      "STDEV.S of the population: 9.977859626765074\n",
      "Accuracy (closer to 100% is more accurate): 100.00500037503124 %\n"
     ]
    }
   ],
   "source": [
    "# Get a sample of 20% of the total.\n",
    "sampleOfData = np.random.choice(data, 2000)\n",
    "\n",
    "stdSSample = STDEV_S(sampleOfData)\n",
    "stdSPopulation = STDEV_S(data)\n",
    "stdPPopulation = STDEV_P(data)\n",
    "\n",
    "# Compare the two values to STDEV.P being used on the whole population.\n",
    "print(\"STDEV.P of the population\", stdPPopulation);\n",
    "\n",
    "# Get the standard deviation using STDEV.S on a sample and the whole population and compare it to STDEV.P being used on the population.\n",
    "print(\"\\nSTDEV.S of the sample data:\", stdSSample)\n",
    "print(\"Accuracy (closer to 100% is more accurate):\", (stdSSample / stdPPopulation) * 100, \"%\")\n",
    "\n",
    "print(\"\\nSTDEV.S of the population:\", stdSPopulation)\n",
    "print(\"Accuracy (closer to 100% is more accurate):\", (stdSPopulation / stdPPopulation) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Although the task wanted to show that using STDEV.S is a better estimate for the standard deviation of a population when it is performed on a sample, my simulations prove more often than not, that using STDEV.S on the population rather on a sample brings a result closer to STDEV.P being used on the population. This is due to the variance that a sample can bring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[10] STDEV.S function; Remarks; https://support.microsoft.com/en-us/office/stdev-s-function-7d69cf97-0c1f-4acf-be27-f3e83904cc23\n",
    "\n",
    "[11] Population and sample standard deviation review; Population and sample standard deviation; https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/variance-standard-deviation-sample/a/population-and-sample-standard-deviation-review;\n",
    "\n",
    "[12] 68–95–99.7 rule; https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Task 4: NB – when I first posted this task, I accidentally wrote “*k*-means” where I meant to write “*k*NN” for *k* Nearest Neighbours. Because of this, I will allow either algorithm to be used and have extended the deadline by two weeks. Use ```scikit-learn``` to apply k-means clustering to Fisher’s famous Iris data set. You will easily obtain a copy of the data set online. Explain in a Markdown cell how your code works and how accurate it might be, and then explain how your model could be used to make predictions of species of iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research\n",
    "```scikit-learn``` is a machine learning library for Python [14].\n",
    "\n",
    "Clustering is the task of dividing the population or data points into several groups such that data points in the same groups are more similar to other data points in the same group and dissimilar to the data points in other groups. It is a collection of objects based on similarity and dissimilarity between them [17].\n",
    "\n",
    "*K*-nearest neighbours is a supervised learning algorithm. *K*-nearest neighbours is a model that classifies data points based on the points that are most similar to it. It uses test data to make an “educated guess” on what an unclassified point should be classified as [19].\n",
    "\n",
    "*K*-means clustering is an unsupervised learning algorithm. The *k*-means algorithm starts by randomly choosing a centroid value for each cluster. The algorithm then performs three steps: (i) Find the Euclidean distance between each data instance and centroids of all the clusters; (ii) Assign the data instances to the cluster of the centroid with the nearest distance; (iii) Calculate new centroid values based on the mean values of the coordinates of all the data instances from the corresponding cluster [16].\n",
    "\n",
    "#### Difference Between Supervised and Unsupervised Learning\n",
    "In supervised learning, the algorithm learns on a labelled dataset, providing an answer key that the algorithm can use to evaluate its accuracy on training data while an unsupervised model provides unlabelled data that the algorithm tries to make sense of by extracting features and patterns on its own [15].\n",
    "\n",
    "### Fisher's Iris Data\n",
    "Fisher's iris data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other [18].\n",
    "<img src=\"https://miro.medium.com/max/3500/1*f6KbPXwksAliMIsibFyGJw.png\" title=\"Iris sepals and petals\" alt=\"Iris sepals and petals\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "Iris data\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      "Iris target_names (iris species)\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Iris target\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# https://heartbeat.fritz.ai/k-means-clustering-using-sklearn-and-python-4a054d67b187\n",
    "\n",
    "# Get the iris data set.\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Column names.\n",
    "print(\"Column names\")\n",
    "print(iris.feature_names)\n",
    "\n",
    "# Iris data.\n",
    "print(\"\\nIris data\")\n",
    "print(iris.data)\n",
    "\n",
    "# Label names.\n",
    "print(\"\\nIris target_names (iris species)\")\n",
    "print(iris.target_names)\n",
    "\n",
    "# Labels.\n",
    "print(\"\\nIris target\")\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.9333333333333333,\n",
       " 2: 0.9333333333333333,\n",
       " 3: 0.9666666666666667,\n",
       " 4: 0.9666666666666667,\n",
       " 5: 0.9666666666666667,\n",
       " 6: 0.9666666666666667,\n",
       " 7: 0.9666666666666667,\n",
       " 8: 0.9666666666666667,\n",
       " 9: 0.9666666666666667,\n",
       " 10: 0.9666666666666667,\n",
       " 11: 0.9666666666666667,\n",
       " 12: 0.9666666666666667,\n",
       " 13: 0.9666666666666667,\n",
       " 14: 0.9666666666666667,\n",
       " 15: 0.9666666666666667,\n",
       " 16: 0.9666666666666667,\n",
       " 17: 0.9666666666666667,\n",
       " 18: 0.9666666666666667,\n",
       " 19: 0.9666666666666667,\n",
       " 20: 0.9333333333333333,\n",
       " 21: 0.9666666666666667,\n",
       " 22: 0.9333333333333333,\n",
       " 23: 0.9666666666666667,\n",
       " 24: 0.9666666666666667,\n",
       " 25: 0.9666666666666667}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/knn-using-scikit-learn-c6bed765be75\n",
    "\n",
    "# Set data and target to variables.\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into 80% training and 20% testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 4)\n",
    "\n",
    "# Find the optimal k value using a for loop and print out their accuracy.\n",
    "k_range = range(1, 26)\n",
    "scores = {}\n",
    "scores_list = []\n",
    "\n",
    "for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        scores[k] = metrics.accuracy_score(y_test, y_pred)\n",
    "        scores_list.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the input data of [[4.7, 3.1, 1.7, 0.4]] is: setosa\n",
      "Prediction for the input data of [[6.7, 3.5, 5.5, 2.0]] is: virginica\n",
      "Prediction for the input data of [[4.5, 2.5, 4.2, 1.7]] is: versicolor\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Set 0 = setosa, 1 = versicolor, 2 = virginica.\n",
    "classes = {0: \"setosa\", 1: \"versicolor\", 2: \"virginica\"}\n",
    "\n",
    "# Predicting on data.\n",
    "testValues1 = [[4.7, 3.1, 1.7, 0.4]]\n",
    "testValues2 = [[6.7, 3.5, 5.5, 2.0]]\n",
    "testValues3 = [[4.5, 2.5, 4.2, 1.7]]\n",
    "\n",
    "prediction = knn.predict(testValues1)\n",
    "print(\"Prediction for the input data of\", testValues1, \"is:\", classes[prediction[0]])\n",
    "\n",
    "prediction = knn.predict(testValues2)\n",
    "print(\"Prediction for the input data of\", testValues2, \"is:\", classes[prediction[0]])\n",
    "\n",
    "prediction = knn.predict(testValues3)\n",
    "print(\"Prediction for the input data of\", testValues3, \"is:\", classes[prediction[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Explaination\n",
    "After setting the iris data and iris target to variables, we have to train and test the data. The test size is set to 20% of the data and the train size is set to 80% of the data. Choosing the optimal k value is critical. The code tests the possible k-values from 1 to 25. In general, as the k value increases there appears to be an increase in the accuracy and then a decrease in the accuracy. For this model, the optimal k value chosen was 6. 6 was set as ```n_neighbors```. A prediction is made with test data and the predicted species of this iris is shown for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Accuracy\n",
    "The accuracy of the prediction can be using a confusion matrix, precision, recall and f1 score [21].\n",
    "\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known [22].\n",
    "\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positive observations [22].\n",
    "$$ Precision = \\frac{True Positive}{True Positive + False Positive}$$\n",
    "<br>\n",
    "\n",
    "Recall is the ratio of correctly predicted positive observations to all the observations in the class [22].\n",
    "$$ Recall = \\frac{True Positive}{True Positive + False Negative} $$\n",
    "<br>\n",
    "\n",
    "F1 Score is the weighted average of precision and recall. This score takes both false positives and false negatives into account [22].\n",
    "$$ F1 Score = 2 \\times \\frac {Recall \\times Precision}{Recall + Precision} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0  4  1]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.93      0.95        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results above, with 0.00 being 0% accurate and 1.00 being 100% accurate, the model created is very accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the Model Could Be Used To Make Predictions of Species of Iris\n",
    "The model can be used to predict a species of iris by allowing the user to enter four different values in a list ```inputValues``` and assign it to ```prediction = knn.predict(inputValues)``` then output ```classes[prediction[0]]```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[14] scikit-learn; https://en.wikipedia.org/wiki/Scikit-learn;\n",
    "\n",
    "[15] SuperVize Me: What’s the Difference Between Supervised, Unsupervised, Semi-Supervised and Reinforcement Learning?; https://blogs.nvidia.com/blog/2018/08/02/supervised-unsupervised-learning/;\n",
    "\n",
    "[16] K-Means Clustering with Scikit-Learn; Introduction; https://stackabuse.com/k-means-clustering-with-scikit-learn/;\n",
    "\n",
    "[17] Clustering in Machine Learning; Introduction to Clustering; https://www.geeksforgeeks.org/clustering-in-machine-learning/;\n",
    "\n",
    "[18] Iris flower data set; https://en.wikipedia.org/wiki/Iris_flower_data_set;\n",
    "\n",
    "[19] K-Nearest Neighbors (KNN) Algorithm for Machine Learning; Introduction; https://medium.com/capital-one-tech/k-nearest-neighbors-knn-algorithm-for-machine-learning-e883219c8f26;\n",
    "\n",
    "[20] MachineLearning — KNN using scikit-learn; https://towardsdatascience.com/knn-using-scikit-learn-c6bed765be75;\n",
    "\n",
    "[21] K-Nearest Neighbors Algorithm in Python and Scikit-Learn; Evaluating the Algorithm; https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/;\n",
    "\n",
    "[22] Accuracy, Precision, Recall & F1 Score: Interpretation of Performance Measures; https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
